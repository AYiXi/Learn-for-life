### *2020-01-02*
>- [REALI] 检查专利的更新情况
>- [REALI] 完成部分网站的政务平台公告的爬虫 (36 / 37)

### *2020-01-03*
>- [REALI] 基本完成政务平台公告爬虫的架构和设计, 可能还有需要修改的细节
>- [REALI] 修改一些源码的默认参数, json 和 logging 的编码都默认设置为 utf8

### *2020-01-06*
>- [REALI] 完成网站的政务平台公告的爬虫
>- [REALI] 对 django 用户系统的学习和开发

### *2020-01-07*
>- [LEARN] 学习了解 `show full processlist`; 和 `kill` 命令

### *2020-01-08*
>- [REALI] 更新专利信息并与王天勇讲解演示
>- [REALI] 更新西青区项目的专利数据
>- [REALI] 检查专利的更新情况
>- [REALI] 完成政务平台的部署和展示
>- [REALI] 对用户系统和权限系统的开发
>- [LEARN] 对 vscode 无法跟踪代码的设置
>- [LEARN] 对 `rest_framework` 的权限系统的了解

### *2020-01-09*
>- [REALI] 书写更新数据的文档
>- [LEARN] 查看 django 的源码, 包括 view, form等, 大概能看懂一些
>- [LEARN] 学习 classmethod 的实现方式和用法
>- [REALI] 使用 selenium 配合 firefox 对国资局进行爬取, 已初步见到成效

### *2020-01-10*
>- [REALI] `dict.setdefault(key, value)` 如果 key 存在, 则 value 不变
>- [LEARN] 学习 django 部分源码
>- [LEARN] 学习 pyppeteer
>- [REALI] 开发用户注册模块

### *2020-01-14*
>- [REALI] 完成除验证手机号之外的用户模块
>- [LEARN] 学习 django 部分源码
>- [REALI] 对国资局爬虫的浏览器结合代码方法的研究, 发现另外的加密参数, 暂时不能通过先浏览器再代码的方式获取到想要的数据, 可能需要考虑纯浏览器请求了

### *2020-01-15*
>- [REALI] 对国资局的 Firefox 爬虫进行编码, 可以实现查询功能, 还需要考虑部署和稳定性
>- [LEARN] 深入的学习了 selenium 的各种 api

### *2020-01-16*
>- [REALI] 检查专利数据正确性
>- [REALI] 国资局爬虫项目:
>- 本地可以通过登录爬虫查询专利了, 一个登录状态能查询 165 个专利号, 之后需要换号登录
>   - 服务器端使用模拟浏览器登录有几个问题
>       - 网速太差导致请求经常失败
>       - 一旦开始运行程序会导致服务器 CPU 资源占用瞬间达到 99%, 会影响其他进程
>   - 目前解决思路:
>       - 本地请求, 然后通过 redis 数据库与服务器同步, 这样就不能关闭本地的电脑很运行的程序
>       - 尝试其他模拟浏览器登录的方案, 不过资源消耗应该是差不多
>- [LEARN] 学习 selenium, pyppeteer

### *2020-01-17*
[REALI]
- 学习使用 redis 作为国资局爬虫的缓存
- 完成最基本的国资局爬虫, 能通过输入专利号查询专利信息, 但是速度有点慢, 大概查询一次要 6-7s, 有优化的空间
- 初步完成通过专利号查询专利信息的接口的架构, 使用 本地浏览器+redis缓存 
- 已经查询过的专利会在缓存中, 下一次再查寻同样的专利号会无延迟
- 目前还有很多地方需要优化:
    - 爬虫过期时效问题, 大概每15分钟, 或者查询 165 次就会失效, 需要重新登陆
    - 缓存数据库的时效问题, 过期时间和刷新时间
    - 验证码平台登录的费用问题, 是否需要一直登录, 还需要和后端商量
    - 是否需要接入中利汇的专利爬虫, 这样就会有两套方案, 返回速度也会更快
    - 代码逻辑结构如何优化
- 国资局自动下载excel测试可行, 但是还有也一些问题, 比如每下载完成一个表之后, 就会报错
[LEARN]
- `redis` 的相关操作
- `pyppeteer` 的大致操作

### *2020-01-20*
[REALI]
- 对数据存储到 redis 中进行压缩研究, 使用 pickle 压缩数据比之前节约了近一倍的容量, 这样网络传输时间更少, 返回更快
- 对国资局爬虫的各项参数的调整和验证, 发现每个账号每天能查询 165 个专利, 并且不受时间限制
- 完成对多个网页同时提取的代码, 现在基本上一个请求可以在 2-3s 返回数据
'- 有个问导致返回时不时为空, 进行调试后发现主要是等待时间不够 js 执行完成, 但是直接加长等待时间会使得每个请求等待时间都长, 降低了效率, 对此针对性优化的思考是': '重写提取数据的代码, 明天将会做这部分的工作',
[LEARN]
- 学习 Hadoop 的概念和基本结构

### *2020-01-21*
[REALI]
- 对查询时间的优化, 通过一个申请号查询费用信息api基本可用, 每个请求第一次查询大约耗时2.5s, 之后有缓存, 返回时间缩短至30ms
- 整合代码到线上, 通过 http://39.105.72.96:9003/?sqh=201910648227X 这个网址可以查询专利号的费用, 发文, 状态等所有信息, 只需要更改专利号即可
[LEARN]
- 学习 Hadoop 的安装与一些流程