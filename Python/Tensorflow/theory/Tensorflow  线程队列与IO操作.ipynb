{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 同步处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.2\n",
      "33.3\n",
      "34.1\n"
     ]
    }
   ],
   "source": [
    "# 模拟一下同步先处理数据，然后才能取数据训练\n",
    "# tensorflow当中，运行操作有依赖性\n",
    "\n",
    "# 1、首先定义队列\n",
    "Q = tf.FIFOQueue(3, tf.float32)\n",
    "\n",
    "# 放入一些数据\n",
    "enq_many = Q.enqueue_many([[0.1, 0.2, 0.3], ])\n",
    "\n",
    "# 2、定义一些处理数据的螺距，取数据的过程      取数据，+1， 入队列\n",
    "\n",
    "out_q = Q.dequeue()\n",
    "\n",
    "data = out_q + 1\n",
    "\n",
    "en_q = Q.enqueue(data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 初始化队列\n",
    "    sess.run(enq_many)\n",
    "\n",
    "    # 处理数据\n",
    "    for i in range(100):\n",
    "        sess.run(en_q)\n",
    "\n",
    "    # 训练数据\n",
    "    for i in range(Q.size().eval()):\n",
    "        print(sess.run(Q.dequeue()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 异步处理数据\n",
    "## 线程协调器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "48.0\n",
      "95.0\n",
      "127.0\n",
      "144.0\n",
      "187.0\n",
      "212.0\n",
      "251.0\n",
      "299.0\n",
      "336.0\n",
      "376.0\n",
      "391.0\n",
      "415.0\n",
      "447.0\n",
      "475.0\n",
      "509.0\n",
      "548.0\n",
      "580.0\n",
      "619.0\n",
      "655.0\n",
      "688.0\n",
      "709.0\n",
      "743.0\n",
      "761.0\n",
      "778.0\n",
      "818.0\n",
      "850.0\n",
      "874.0\n",
      "910.0\n",
      "930.0\n",
      "974.0\n",
      "1023.0\n",
      "1024.0\n",
      "1025.0\n",
      "1026.0\n",
      "1027.0\n",
      "1028.0\n",
      "1029.0\n",
      "1030.0\n",
      "1031.0\n",
      "1032.0\n",
      "1033.0\n",
      "1034.0\n",
      "1035.0\n",
      "1036.0\n",
      "1037.0\n",
      "1038.0\n",
      "1039.0\n",
      "1040.0\n",
      "1041.0\n",
      "1042.0\n",
      "1043.0\n",
      "1044.0\n",
      "1045.0\n",
      "1046.0\n",
      "1047.0\n",
      "1048.0\n",
      "1049.0\n",
      "1050.0\n",
      "1051.0\n",
      "1052.0\n",
      "1053.0\n",
      "1054.0\n",
      "1055.0\n",
      "1056.0\n",
      "1057.0\n",
      "1058.0\n",
      "1059.0\n",
      "1060.0\n",
      "1061.0\n",
      "1062.0\n",
      "1063.0\n",
      "1064.0\n",
      "1065.0\n",
      "1066.0\n",
      "1067.0\n",
      "1068.0\n",
      "1069.0\n",
      "1070.0\n",
      "1071.0\n",
      "1072.0\n",
      "1073.0\n",
      "1074.0\n",
      "1075.0\n",
      "1076.0\n",
      "1077.0\n",
      "1078.0\n",
      "1079.0\n",
      "1080.0\n",
      "1081.0\n",
      "1082.0\n",
      "1083.0\n",
      "1084.0\n",
      "1085.0\n",
      "1086.0\n",
      "1087.0\n",
      "1088.0\n",
      "1089.0\n",
      "1090.0\n",
      "1092.0\n",
      "1092.0\n",
      "1093.0\n",
      "1094.0\n",
      "1095.0\n",
      "1096.0\n",
      "1097.0\n",
      "1098.0\n",
      "1099.0\n",
      "1100.0\n",
      "1101.0\n",
      "1102.0\n",
      "1103.0\n",
      "1104.0\n",
      "1105.0\n",
      "1106.0\n",
      "1108.0\n",
      "1108.0\n",
      "1109.0\n",
      "1110.0\n",
      "1111.0\n",
      "1112.0\n",
      "1113.0\n",
      "1114.0\n",
      "1115.0\n",
      "1116.0\n",
      "1117.0\n",
      "1118.0\n",
      "1119.0\n",
      "1120.0\n",
      "1121.0\n",
      "1122.0\n",
      "1123.0\n",
      "1124.0\n",
      "1125.0\n",
      "1126.0\n",
      "1127.0\n",
      "1128.0\n",
      "1129.0\n",
      "1130.0\n",
      "1131.0\n",
      "1132.0\n",
      "1133.0\n",
      "1135.0\n",
      "1135.0\n",
      "1136.0\n",
      "1137.0\n",
      "1138.0\n",
      "1139.0\n",
      "1140.0\n",
      "1141.0\n",
      "1142.0\n",
      "1143.0\n",
      "1144.0\n",
      "1145.0\n",
      "1146.0\n",
      "1147.0\n",
      "1148.0\n",
      "1149.0\n",
      "1150.0\n",
      "1151.0\n",
      "1152.0\n",
      "1153.0\n",
      "1155.0\n",
      "1155.0\n",
      "1156.0\n",
      "1157.0\n",
      "1158.0\n",
      "1159.0\n",
      "1160.0\n",
      "1162.0\n",
      "1162.0\n",
      "1163.0\n",
      "1164.0\n",
      "1165.0\n",
      "1166.0\n",
      "1167.0\n",
      "1168.0\n",
      "1169.0\n",
      "1170.0\n",
      "1171.0\n",
      "1172.0\n",
      "1173.0\n",
      "1174.0\n",
      "1175.0\n",
      "1177.0\n",
      "1177.0\n",
      "1178.0\n",
      "1179.0\n",
      "1180.0\n",
      "1181.0\n",
      "1182.0\n",
      "1183.0\n",
      "1184.0\n",
      "1186.0\n",
      "1186.0\n",
      "1187.0\n",
      "1188.0\n",
      "1189.0\n",
      "1190.0\n",
      "1191.0\n",
      "1192.0\n",
      "1193.0\n",
      "1194.0\n",
      "1195.0\n",
      "1196.0\n",
      "1197.0\n",
      "1198.0\n",
      "1199.0\n",
      "1200.0\n",
      "1201.0\n",
      "1202.0\n",
      "1203.0\n",
      "1204.0\n",
      "1205.0\n",
      "1206.0\n",
      "1207.0\n",
      "1208.0\n",
      "1209.0\n",
      "1210.0\n",
      "1211.0\n",
      "1212.0\n",
      "1213.0\n",
      "1214.0\n",
      "1215.0\n",
      "1217.0\n",
      "1217.0\n",
      "1218.0\n",
      "1219.0\n",
      "1220.0\n",
      "1221.0\n",
      "1222.0\n",
      "1224.0\n",
      "1224.0\n",
      "1225.0\n",
      "1226.0\n",
      "1227.0\n",
      "1228.0\n",
      "1229.0\n",
      "1230.0\n",
      "1231.0\n",
      "1232.0\n",
      "1233.0\n",
      "1234.0\n",
      "1235.0\n",
      "1236.0\n",
      "1237.0\n",
      "1238.0\n",
      "1239.0\n",
      "1240.0\n",
      "1241.0\n",
      "1242.0\n",
      "1243.0\n",
      "1244.0\n",
      "1245.0\n",
      "1246.0\n",
      "1248.0\n",
      "1248.0\n",
      "1249.0\n",
      "1250.0\n",
      "1251.0\n",
      "1252.0\n",
      "1253.0\n",
      "1254.0\n",
      "1255.0\n",
      "1256.0\n",
      "1257.0\n",
      "1258.0\n",
      "1259.0\n",
      "1260.0\n",
      "1261.0\n",
      "1262.0\n",
      "1263.0\n",
      "1264.0\n",
      "1265.0\n",
      "1266.0\n",
      "1267.0\n",
      "1268.0\n",
      "1269.0\n",
      "1270.0\n",
      "1272.0\n",
      "1272.0\n",
      "1273.0\n",
      "1274.0\n",
      "1275.0\n",
      "1276.0\n",
      "1277.0\n",
      "1278.0\n",
      "1279.0\n",
      "1280.0\n",
      "1281.0\n",
      "1282.0\n",
      "1283.0\n",
      "1284.0\n",
      "1285.0\n",
      "1286.0\n",
      "1288.0\n",
      "1288.0\n",
      "1289.0\n",
      "1290.0\n",
      "1291.0\n"
     ]
    }
   ],
   "source": [
    "# 模拟异步子线程 存入样本， 主线程 读取样本\n",
    "\n",
    "# 1、定义一个队列，1000\n",
    "Q = tf.FIFOQueue(1000, tf.float32)\n",
    "\n",
    "# 2、定义要做的事情 循环 值，+1， 放入队列当中\n",
    "var = tf.Variable(0.0)\n",
    "\n",
    "# 实现一个自增  tf.assign_add\n",
    "data = tf.assign_add(var, tf.constant(1.0))\n",
    "\n",
    "en_q = Q.enqueue(data)\n",
    "\n",
    "# 3、定义队列管理器op, 指定多少个子线程，子线程该干什么事情\n",
    "qr = tf.train.QueueRunner(Q, enqueue_ops=[en_q] * 2)\n",
    "\n",
    "# 初始化变量的OP\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 初始化变量\n",
    "    sess.run(init_op)\n",
    "\n",
    "    # 开启线程管理器\n",
    "    coord = tf.train.Coordinator()\n",
    "\n",
    "    # 真正开启子线程\n",
    "    threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "\n",
    "    # 主线程，不断读取数据训练\n",
    "    for i in range(300):\n",
    "        print(sess.run(Q.dequeue()))\n",
    "\n",
    "    # 回收你\n",
    "    coord.request_stop()\n",
    "\n",
    "    coord.join(threads)\n",
    "\n",
    "\n",
    "# 批处理大小，跟队列，数据的数量没有影响，只决定 这批次取多少数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "53.0\n",
      "81.0\n",
      "115.0\n",
      "140.0\n",
      "177.0\n",
      "201.0\n",
      "244.0\n",
      "278.0\n",
      "299.0\n",
      "326.0\n",
      "376.0\n",
      "401.0\n",
      "456.0\n",
      "477.0\n",
      "504.0\n",
      "540.0\n",
      "581.0\n",
      "619.0\n",
      "635.0\n",
      "658.0\n",
      "677.0\n",
      "719.0\n",
      "771.0\n",
      "805.0\n",
      "830.0\n",
      "861.0\n",
      "901.0\n",
      "946.0\n",
      "981.0\n",
      "1014.0\n",
      "1023.0\n",
      "1024.0\n",
      "1025.0\n",
      "1026.0\n",
      "1027.0\n",
      "1028.0\n",
      "1029.0\n",
      "1030.0\n",
      "1031.0\n",
      "1032.0\n",
      "1033.0\n",
      "1034.0\n",
      "1035.0\n",
      "1036.0\n",
      "1037.0\n",
      "1038.0\n",
      "1039.0\n",
      "1040.0\n",
      "1041.0\n",
      "1042.0\n",
      "1043.0\n",
      "1044.0\n",
      "1045.0\n",
      "1046.0\n",
      "1047.0\n",
      "1048.0\n",
      "1049.0\n",
      "1050.0\n",
      "1051.0\n",
      "1052.0\n",
      "1053.0\n",
      "1054.0\n",
      "1055.0\n",
      "1056.0\n",
      "1057.0\n",
      "1058.0\n",
      "1059.0\n",
      "1060.0\n",
      "1061.0\n",
      "1062.0\n",
      "1064.0\n",
      "1064.0\n",
      "1065.0\n",
      "1066.0\n",
      "1067.0\n",
      "1068.0\n",
      "1069.0\n",
      "1070.0\n",
      "1071.0\n",
      "1072.0\n",
      "1073.0\n",
      "1074.0\n",
      "1075.0\n",
      "1076.0\n",
      "1077.0\n",
      "1078.0\n",
      "1080.0\n",
      "1081.0\n",
      "1081.0\n",
      "1082.0\n",
      "1083.0\n",
      "1084.0\n",
      "1085.0\n",
      "1086.0\n",
      "1087.0\n",
      "1088.0\n",
      "1089.0\n",
      "1090.0\n",
      "1091.0\n",
      "1092.0\n",
      "1093.0\n",
      "1094.0\n",
      "1095.0\n",
      "1096.0\n",
      "1097.0\n",
      "1098.0\n",
      "1099.0\n",
      "1100.0\n",
      "1101.0\n",
      "1102.0\n",
      "1103.0\n",
      "1104.0\n",
      "1105.0\n",
      "1106.0\n",
      "1107.0\n",
      "1108.0\n",
      "1109.0\n",
      "1110.0\n",
      "1111.0\n",
      "1112.0\n",
      "1113.0\n",
      "1114.0\n",
      "1115.0\n",
      "1116.0\n",
      "1117.0\n",
      "1118.0\n",
      "1119.0\n",
      "1120.0\n",
      "1121.0\n",
      "1122.0\n",
      "1123.0\n",
      "1124.0\n",
      "1125.0\n",
      "1126.0\n",
      "1127.0\n",
      "1128.0\n",
      "1129.0\n",
      "1130.0\n",
      "1131.0\n",
      "1132.0\n",
      "1133.0\n",
      "1134.0\n",
      "1135.0\n",
      "1136.0\n",
      "1137.0\n",
      "1138.0\n",
      "1139.0\n",
      "1140.0\n",
      "1141.0\n",
      "1142.0\n",
      "1143.0\n",
      "1144.0\n",
      "1145.0\n",
      "1147.0\n",
      "1147.0\n",
      "1148.0\n",
      "1149.0\n",
      "1150.0\n",
      "1151.0\n",
      "1152.0\n",
      "1153.0\n",
      "1154.0\n",
      "1155.0\n",
      "1156.0\n",
      "1157.0\n",
      "1158.0\n",
      "1159.0\n",
      "1160.0\n",
      "1161.0\n",
      "1162.0\n",
      "1163.0\n",
      "1164.0\n",
      "1165.0\n",
      "1166.0\n",
      "1167.0\n",
      "1168.0\n",
      "1169.0\n",
      "1170.0\n",
      "1171.0\n",
      "1172.0\n",
      "1173.0\n",
      "1174.0\n",
      "1175.0\n",
      "1176.0\n",
      "1177.0\n",
      "1178.0\n",
      "1179.0\n",
      "1180.0\n",
      "1181.0\n",
      "1182.0\n",
      "1183.0\n",
      "1184.0\n",
      "1185.0\n",
      "1186.0\n",
      "1187.0\n",
      "1188.0\n",
      "1189.0\n",
      "1190.0\n",
      "1191.0\n",
      "1192.0\n",
      "1193.0\n",
      "1194.0\n",
      "1195.0\n",
      "1196.0\n",
      "1197.0\n",
      "1198.0\n",
      "1199.0\n",
      "1200.0\n",
      "1201.0\n",
      "1202.0\n",
      "1203.0\n",
      "1204.0\n",
      "1205.0\n",
      "1206.0\n",
      "1207.0\n",
      "1208.0\n",
      "1209.0\n",
      "1210.0\n",
      "1211.0\n",
      "1212.0\n",
      "1213.0\n",
      "1214.0\n",
      "1215.0\n",
      "1216.0\n",
      "1217.0\n",
      "1218.0\n",
      "1219.0\n",
      "1220.0\n",
      "1221.0\n",
      "1222.0\n",
      "1223.0\n",
      "1224.0\n",
      "1225.0\n",
      "1226.0\n",
      "1227.0\n",
      "1228.0\n",
      "1229.0\n",
      "1230.0\n",
      "1231.0\n",
      "1232.0\n",
      "1233.0\n",
      "1234.0\n",
      "1235.0\n",
      "1236.0\n",
      "1237.0\n",
      "1238.0\n",
      "1239.0\n",
      "1240.0\n",
      "1241.0\n",
      "1242.0\n",
      "1243.0\n",
      "1244.0\n",
      "1245.0\n",
      "1246.0\n",
      "1247.0\n",
      "1248.0\n",
      "1249.0\n",
      "1250.0\n",
      "1251.0\n",
      "1252.0\n",
      "1253.0\n",
      "1254.0\n",
      "1255.0\n",
      "1256.0\n",
      "1257.0\n",
      "1258.0\n",
      "1259.0\n",
      "1260.0\n",
      "1261.0\n",
      "1263.0\n",
      "1263.0\n",
      "1264.0\n",
      "1265.0\n",
      "1266.0\n",
      "1267.0\n",
      "1268.0\n",
      "1269.0\n",
      "1270.0\n",
      "1272.0\n",
      "1272.0\n",
      "1273.0\n",
      "1274.0\n",
      "1275.0\n",
      "1276.0\n",
      "1277.0\n",
      "1279.0\n",
      "1279.0\n",
      "1280.0\n",
      "1281.0\n",
      "1282.0\n",
      "1283.0\n",
      "1284.0\n",
      "1285.0\n",
      "1286.0\n",
      "1287.0\n",
      "1288.0\n",
      "1289.0\n",
      "1291.0\n",
      "1291.0\n"
     ]
    }
   ],
   "source": [
    "Q = tf.FIFOQueue(1000, tf.float32)\n",
    "\n",
    "var = tf.Variable(0.0, tf.float32)\n",
    "\n",
    "data = tf.assign_add(var, tf.constant(1.0))\n",
    "\n",
    "en_q = Q.enqueue(data)\n",
    "\n",
    "qr = tf.train.QueueRunner(Q, enqueue_ops=[en_q] * 2)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    \n",
    "    threads = qr.create_threads(sess=sess,coord=coord, start=True)\n",
    "    \n",
    "    for i in range(300):\n",
    "        print(sess.run(Q.dequeue()))\n",
    "        \n",
    "    coord.request_stop()\n",
    "    \n",
    "    coord.join(threads=threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文件读取流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"batch_3:0\", shape=(12,), dtype=string) Tensor(\"batch_3:1\", shape=(12,), dtype=float32)\n",
      "[b'a1', 1.0]\n",
      "[array([b'a2', b'a3', b'b4', b'b5', b'b6', b'b4', b'b5', b'b6', b'a1',\n",
      "       b'a2', b'a3', b'a1'], dtype=object), array([2., 3., 4., 5., 6., 4., 5., 6., 1., 2., 3., 1.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#     读取CSV文件\n",
    "#     :param filelist: 文件路径+名字的列表\n",
    "#     :return: 读取的内容\n",
    "filelist = ['./a.csv', './b.csv']\n",
    "\n",
    "# 1、构造文件的队列\n",
    "file_queue = tf.train.string_input_producer(filelist)\n",
    "\n",
    "# 2、构造csv阅读器读取队列数据（按一行）\n",
    "reader = tf.TextLineReader()\n",
    "\n",
    "key, value = reader.read(file_queue)\n",
    "# print(key, value)\n",
    "\n",
    "# 3、对每行内容解码\n",
    "# record_defaults:指定每一个样本的每一列的类型，指定默认值[[\"None\"], [4.0]]\n",
    "records = [[\"None\"], [1.0]]\n",
    "\n",
    "example, label = tf.decode_csv(value, record_defaults=records)\n",
    "\n",
    "# 4、想要读取多个数据，就需要批处理\n",
    "example_batch, label_batch = tf.train.batch([example, label], batch_size=12, num_threads=1, capacity=9)\n",
    "\n",
    "print(example_batch, label_batch)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    \n",
    "    threads = tf.train.start_queue_runners(sess, coord=coord)\n",
    "    \n",
    "    print(sess.run([example, label]))\n",
    "    \n",
    "    print(sess.run([example_batch, label_batch]))\n",
    "    \n",
    "    coord.request_stop()\n",
    "    \n",
    "    coord.join(threads=threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: Tensor(\"ReaderReadV2_4:1\", shape=(), dtype=string)\n",
      "\n",
      "image: Tensor(\"DecodeJpeg_1:0\", shape=(?, ?, ?), dtype=uint8)\n",
      "\n",
      "image_resize: Tensor(\"resize_images_1/Squeeze:0\", shape=(200, 200, ?), dtype=float32)\n",
      "\n",
      "image_resize: Tensor(\"resize_images_1/Squeeze:0\", shape=(200, 200, 3), dtype=float32)\n",
      "\n",
      "image_batch: Tensor(\"batch_4:0\", shape=(20, 200, 200, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "#     读取狗图片并转换成张量\n",
    "#     :param filelist: 文件路径+ 名字的列表\n",
    "#     :return: 每张图片的张量\n",
    "\n",
    "filelist = ['.\\9150e4e5gw1faae2uxkz6j20k00olq3j.jpg']\n",
    "\n",
    "# 1、构造文件队列\n",
    "file_queue = tf.train.string_input_producer(filelist)\n",
    "\n",
    "# 2、构造阅读器去读取图片内容（默认读取一张图片）\n",
    "reader = tf.WholeFileReader()\n",
    "\n",
    "key, value = reader.read(file_queue)\n",
    "\n",
    "print('value:', value)\n",
    "\n",
    "# 3、对读取的图片数据进行解码\n",
    "image = tf.image.decode_jpeg(value)\n",
    "\n",
    "print('\\nimage:', image)\n",
    "\n",
    "# 5、处理图片的大小（统一大小）\n",
    "image_resize = tf.image.resize_images(image, [200, 200])\n",
    "\n",
    "print('\\nimage_resize:', image_resize)\n",
    "\n",
    "# 注意：一定要把样本的形状固定 [200, 200, 3],在批处理的时候要求所有数据形状必须定义\n",
    "image_resize.set_shape([200, 200, 3])\n",
    "\n",
    "print('\\nimage_resize:', image_resize)\n",
    "\n",
    "# 6、进行批处理\n",
    "image_batch = tf.train.batch([image_resize], batch_size=20, num_threads=1, capacity=20)\n",
    "\n",
    "print('\\nimage_batch:', image_batch)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     coord = tf.train.Coordinator()\n",
    "    \n",
    "#     threads = tf.train.start_queue_runners(sess, coord=coord)\n",
    "    \n",
    "#     print(sess.run([example, label]))\n",
    "    \n",
    "#     print(sess.run([example_batch, label_batch]))\n",
    "    \n",
    "#     coord.request_stop()\n",
    "    \n",
    "#     coord.join(threads=threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_string(\"cifar_dir\", \"./data/cifar10/cifar-10-batches-bin/\", \"文件的目录\")\n",
    "tf.app.flags.DEFINE_string(\"cifar_tfrecords\", \"./tmp/cifar.tfrecords\", \"存进tfrecords的文件\")\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "\n",
    "class CifarRead(object):\n",
    "    \"\"\"完成读取二进制文件， 写进tfrecords，读取tfrecords\n",
    "    \"\"\"\n",
    "    def __init__(self, filelist):\n",
    "        # 文件列表\n",
    "        self.file_list = filelist\n",
    "\n",
    "        # 定义读取的图片的一些属性\n",
    "        self.height = 32\n",
    "        self.width = 32\n",
    "        self.channel = 3\n",
    "        # 二进制文件每张图片的字节\n",
    "        self.label_bytes = 1\n",
    "        self.image_bytes = self.height * self.width * self.channel\n",
    "        self.bytes = self.label_bytes + self.image_bytes\n",
    "\n",
    "    def read_and_decode(self):\n",
    "        # 1、构造文件队列\n",
    "        file_queue = tf.train.string_input_producer(self.file_list)\n",
    "\n",
    "        # 2、构造二进制文件读取器，读取内容, 每个样本的字节数\n",
    "        reader = tf.FixedLengthRecordReader(self.bytes)\n",
    "\n",
    "        key, value = reader.read(file_queue)\n",
    "\n",
    "        # 3、解码内容, 二进制文件内容的解码\n",
    "        label_image = tf.decode_raw(value, tf.uint8)\n",
    "\n",
    "        print(label_image)\n",
    "\n",
    "        # 4、分割出图片和标签数据，切除特征值和目标值\n",
    "        label = tf.cast(tf.slice(label_image, [0], [self.label_bytes]), tf.int32)\n",
    "\n",
    "        image = tf.slice(label_image, [self.label_bytes], [self.image_bytes])\n",
    "\n",
    "        # 5、可以对图片的特征数据进行形状的改变 [3072] --> [32, 32, 3]\n",
    "        image_reshape = tf.reshape(image, [self.height, self.width, self.channel])\n",
    "\n",
    "        print(label, image_reshape)\n",
    "        # 6、批处理数据\n",
    "        image_batch, label_batch = tf.train.batch([image_reshape, label], batch_size=10, num_threads=1, capacity=10)\n",
    "\n",
    "        print(image_batch, label_batch)\n",
    "        \n",
    "        return image_batch, label_batch\n",
    "\n",
    "    def write_ro_tfrecords(self, image_batch, label_batch):\n",
    "        \"\"\"\n",
    "        将图片的特征值和目标值存进tfrecords\n",
    "        :param image_batch: 10张图片的特征值\n",
    "        :param label_batch: 10张图片的目标值\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # 1、建立TFRecord存储器\n",
    "        writer = tf.python_io.TFRecordWriter(FLAGS.cifar_tfrecords)\n",
    "\n",
    "        # 2、循环将所有样本写入文件，每张图片样本都要构造example协议\n",
    "        for i in range(10):\n",
    "            # 取出第i个图片数据的特征值和目标值\n",
    "            image = image_batch[i].eval().tostring()\n",
    "\n",
    "            label = int(label_batch[i].eval()[0])\n",
    "\n",
    "            # 构造一个样本的example\n",
    "            example =  tf.train.Example(features=tf.train.Features(feature={\n",
    "                \"image\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n",
    "                \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),\n",
    "            }))\n",
    "\n",
    "            # 写入单独的样本\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "        # 关闭\n",
    "        writer.close()\n",
    "\n",
    "    def read_from_tfrecords(self):\n",
    "        # 1、构造文件队列\n",
    "        file_queue = tf.train.string_input_producer([FLAGS.cifar_tfrecords])\n",
    "\n",
    "        # 2、构造文件阅读器，读取内容example,value=一个样本的序列化example\n",
    "        reader = tf.TFRecordReader()\n",
    "\n",
    "        key, value = reader.read(file_queue)\n",
    "\n",
    "        # 3、解析example\n",
    "        features = tf.parse_single_example(value, features={\n",
    "            \"image\": tf.FixedLenFeature([], tf.string),\n",
    "            \"label\": tf.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "\n",
    "        # 4、解码内容, 如果读取的内容格式是string需要解码， 如果是int64,float32不需要解码\n",
    "        image = tf.decode_raw(features[\"image\"], tf.uint8)\n",
    "\n",
    "        # 固定图片的形状，方便与批处理\n",
    "        image_reshape = tf.reshape(image, [self.height, self.width, self.channel])\n",
    "\n",
    "        label = tf.cast(features[\"label\"], tf.int32)\n",
    "\n",
    "        print(image_reshape, label)\n",
    "\n",
    "        # 进行批处理\n",
    "        image_batch, label_batch = tf.train.batch([image_reshape, label], batch_size=10, num_threads=1, capacity=10)\n",
    "\n",
    "        return image_batch, label_batch\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cf = CifarRead(filelist)\n",
    "\n",
    "    # image_batch, label_batch = cf.read_and_decode()\n",
    "\n",
    "    image_batch, label_batch = cf.read_from_tfrecords()\n",
    "\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        coord = tf.train.Coordinator()\n",
    "\n",
    "        threads = tf.train.start_queue_runners(sess, coord=coord)\n",
    "        \n",
    "        # 存进tfrecords文件\n",
    "        # print(\"开始存储\")\n",
    "        #\n",
    "        # cf.write_ro_tfrecords(image_batch, label_batch)\n",
    "        #\n",
    "        # print(\"结束存储\")\n",
    "        \n",
    "        # 打印读取的内容\n",
    "        print(sess.run([image_batch, label_batch]))\n",
    "\n",
    "        coord.request_stop()\n",
    "\n",
    "        coord.join(threads=threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
